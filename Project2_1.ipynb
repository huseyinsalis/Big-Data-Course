{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\callbacks.py:848: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.5886 - acc: 0.8458 - val_loss: 0.2999 - val_acc: 0.9155\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.2780 - acc: 0.9213 - val_loss: 0.2368 - val_acc: 0.9349\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.2268 - acc: 0.9358 - val_loss: 0.2031 - val_acc: 0.9424\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.1944 - acc: 0.9447 - val_loss: 0.1802 - val_acc: 0.9482\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1698 - acc: 0.9518 - val_loss: 0.1647 - val_acc: 0.9528\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1513 - acc: 0.9571 - val_loss: 0.1556 - val_acc: 0.9542\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1359 - acc: 0.9615 - val_loss: 0.1339 - val_acc: 0.9605\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.1231 - acc: 0.9647 - val_loss: 0.1243 - val_acc: 0.9625\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1122 - acc: 0.9680 - val_loss: 0.1196 - val_acc: 0.9648\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.1028 - acc: 0.9712 - val_loss: 0.1100 - val_acc: 0.9684\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0949 - acc: 0.9732 - val_loss: 0.1097 - val_acc: 0.9686\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0876 - acc: 0.9749 - val_loss: 0.1015 - val_acc: 0.9702\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0810 - acc: 0.9773 - val_loss: 0.0984 - val_acc: 0.9716\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0754 - acc: 0.9788 - val_loss: 0.0917 - val_acc: 0.9725\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0704 - acc: 0.9802 - val_loss: 0.0876 - val_acc: 0.9724\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0653 - acc: 0.9820 - val_loss: 0.0858 - val_acc: 0.9729\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0612 - acc: 0.9827 - val_loss: 0.0833 - val_acc: 0.9747\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0572 - acc: 0.9846 - val_loss: 0.0812 - val_acc: 0.9755\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0536 - acc: 0.9858 - val_loss: 0.0783 - val_acc: 0.9754\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0504 - acc: 0.9862 - val_loss: 0.0765 - val_acc: 0.9763\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0474 - acc: 0.9876 - val_loss: 0.0749 - val_acc: 0.9772\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0446 - acc: 0.9882 - val_loss: 0.0753 - val_acc: 0.9762\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0421 - acc: 0.9889 - val_loss: 0.0728 - val_acc: 0.9772\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0396 - acc: 0.9897 - val_loss: 0.0728 - val_acc: 0.9771\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0374 - acc: 0.9905 - val_loss: 0.0707 - val_acc: 0.9789\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0352 - acc: 0.9909 - val_loss: 0.0704 - val_acc: 0.9786\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0333 - acc: 0.9917 - val_loss: 0.0708 - val_acc: 0.9784\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0313 - acc: 0.9924 - val_loss: 0.0703 - val_acc: 0.9789\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0298 - acc: 0.9928 - val_loss: 0.0682 - val_acc: 0.9797\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0284 - acc: 0.9931 - val_loss: 0.0666 - val_acc: 0.9798\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0267 - acc: 0.9943 - val_loss: 0.0671 - val_acc: 0.9797\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0252 - acc: 0.9946 - val_loss: 0.0677 - val_acc: 0.9795\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0239 - acc: 0.9950 - val_loss: 0.0661 - val_acc: 0.9804\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0227 - acc: 0.9954 - val_loss: 0.0649 - val_acc: 0.9811\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0214 - acc: 0.9959 - val_loss: 0.0661 - val_acc: 0.9802\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0204 - acc: 0.9960 - val_loss: 0.0652 - val_acc: 0.9804\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0194 - acc: 0.9964 - val_loss: 0.0659 - val_acc: 0.9808\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0183 - acc: 0.9969 - val_loss: 0.0653 - val_acc: 0.9799\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0174 - acc: 0.9971 - val_loss: 0.0667 - val_acc: 0.9804\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0165 - acc: 0.9973 - val_loss: 0.0643 - val_acc: 0.9813\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0157 - acc: 0.9976 - val_loss: 0.0653 - val_acc: 0.9807\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0149 - acc: 0.9978 - val_loss: 0.0650 - val_acc: 0.9811\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0141 - acc: 0.9980 - val_loss: 0.0641 - val_acc: 0.9809\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0135 - acc: 0.9980 - val_loss: 0.0633 - val_acc: 0.9812\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0128 - acc: 0.9982 - val_loss: 0.0658 - val_acc: 0.9806\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0123 - acc: 0.9985 - val_loss: 0.0646 - val_acc: 0.9810\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0117 - acc: 0.9986 - val_loss: 0.0648 - val_acc: 0.9804\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0112 - acc: 0.9987 - val_loss: 0.0655 - val_acc: 0.9810\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0106 - acc: 0.9989 - val_loss: 0.0644 - val_acc: 0.9812\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0101 - acc: 0.9990 - val_loss: 0.0653 - val_acc: 0.9809\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0097 - acc: 0.9991 - val_loss: 0.0652 - val_acc: 0.9801\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0093 - acc: 0.9992 - val_loss: 0.0641 - val_acc: 0.9817\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0088 - acc: 0.9992 - val_loss: 0.0646 - val_acc: 0.9815\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0085 - acc: 0.9992 - val_loss: 0.0645 - val_acc: 0.9811\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import datetime\n",
    "import os\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(layers.Dense(300, activation=\"relu\"))\n",
    "model.add(layers.Dense(100, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        run_logdir,                 \n",
    "        histogram_freq=1                                         \n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(patience=10,\n",
    "                                    restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=100,\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    callbacks=callbacks)\n",
    "model.save(\"f_minst.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
